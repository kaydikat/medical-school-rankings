# We Need Better Medical School Rankings

Medical school rankings have entered a confusing new era. After Harvard and other elite programs [withdrew from *U.S. News & World Report*](https://observer.com/2023/01/harvard-leads-an-exodus-of-medical-schools-withdrawing-from-us-news-rankings/), the system shifted to broad tiers—essentially buckets of schools [with minimal differentiation](https://www.chronicle.com/article/u-s-news-medical-school-rankings-are-out-except-theyre-not-really-rankings). While the stated goals around [promoting diversity](https://www.mountsinai.org/about/newsroom/2023/us-news-medical-school-rankings) and avoiding reductive comparisons are laudable, this change has created **less transparency** for prospective students and **fewer incentives** for schools to cater to student priorities.

Yes, all accredited U.S. medical schools produce qualified physicians. But dismissing rankings entirely ignores their practical value: helping students identify target programs with high quality clinical training and cutting-edge research; encouraging schools to innovate to attract top applicants; and providing evidence of program selectivity to residency directors or future employers.

Here's the paradox: just as medical schools moved away from rankings, residency programs began leaning *more heavily* on medical school prestige. USMLE Step 1 [shifted to pass/fail](https://www.doximity.com/articles/210fde6e-2ce2-43c8-b35b-c3a2b55f5903), eliminating a key metric. Now residency directors [increasingly rely on the reputation of applicants' medical schools](https://doi.org/10.1016/j.wneu.2020.07.053) to evaluate candidates. Medical schools want to de-emphasize rankings precisely when reputation matters most to their graduates' career prospects.

## The Case for Reformed Rankings

**1. Elite Schools Are Pulling Up the Ladder**

When top programs withdrew, they protected their reputations while making it nearly impossible for rising schools to prove their worth. The University of South Florida's incoming class [now outscores Harvard and Stanford](https://www.usf.edu/health/delivering-health-excellence/2025/usnwr-mcom-2025.aspx#:~:text=Our%20incoming%20students%E2%80%99%20median%20MCAT%20scores%20have%20soared%3B%20this%20year%E2%80%99s%20class%20median%20score%20is%20520%2C%20placing%20them%20among%20the%20top%203%25%20of%20students%20nationwide.) on MCAT and GPA—yet without rankings, USF remains overshadowed by legacy prestige. In a world with pass/fail grades, pass/fail Step 1, and no rankings, will residency program directors recognize talented students from less-known schools?

The irony is striking: Columbia's dean condemned rankings as ["perpetuat[ing] a narrow and elitist perspective on medical education"](https://www.cuimc.columbia.edu/news/medical-school-rankings#:~:text=Physicians%20and%20Surgeons.-,The%20USNWR%20medical%20school%20rankings%20perpetuate%20a%20narrow%20and%20elitist%20perspective%20on%20medical%20education.,-Their%20emphasis%20is)—yet by withdrawing, elite schools have *entrenched* that very elitism. Their reputations remain unassailable while rising programs lose any pathway to recognition.

As Harvard medical student [Aditya Jain writes](https://opmed.doximity.com/articles/the-medical-school-rankings-mess-a-lose-lose-for-students-and-schools): "Elite medical schools gain a great advantage without formal rankings... By refusing to participate, these prestigious institutions are essentially pulling up the ladder behind them."

**2. Competition Drives Student-Centered Innovation**

NYU Grossman's [decision to eliminate tuition](https://www.nytimes.com/2018/08/16/nyregion/nyu-free-tuition-medical-school.html) catapulted them to [#2 nationally](https://nyulangone.org/news/321-impossible-math-it-all-adds-nyu-langone-health#:~:text=NYU%20Grossman%20School%20of%20Medicine%20climbed%20to%20the%20No.%202%20spot%20for%20research%20on%20U.S.%20News%20%26%20World%20Report%E2%80%99s%202022%E2%80%9323) and triggered a nationwide response: Washington University [committed $100 million](https://medicine.washu.edu/news/washington-university-commits-100-million-to-md-scholarships-education/) to scholarships for most students, Albert Einstein went permanently [tuition-free](https://www.nytimes.com/2024/02/26/nyregion/albert-einstein-college-medicine-bronx-donation.html), Johns Hopkins became [tuition-free for many](https://hub.jhu.edu/2024/07/08/johns-hopkins-investment-financial-aid-medical-students/), and schools like Columbia and Yale dramatically [expanded financial aid](https://medicine.yale.edu/news-article/debt-free-medical-education-ysms-vision-for-the-future/).

Rankings create a feedback loop between student preferences and school behavior. If schools stop attracting strong applicants, their rankings *should* drop—that signal tells you the school isn't serving students well. Remove this feedback loop, and the power imbalance tilts entirely toward institutions.

**3. The Rankings Vacuum will be Filled—One Way or Another**

Without official rankings, informal systems have proliferated, often with [poorly documented methodologies](https://med.admit.org/school-rankings) or [questionable incentives](https://nyunews.com/news/2025/10/28/grossman-woke-ranking/).

## Our Solution: Transparent, Community-Driven Rankings

We use **exclusively public data** with **community-sourced weights**:

- **Academics:** GPA, MCAT
- **Research:** NIH funding total and per faculty  
- **Finances:** Tuition, debt, total cost
- **Clinical Excellence:** Specialty reputation
- **Student Body:** Representation in medicine

No peer assessment popularity contests. No hidden methodology. The community determines category importance through crowdsourced median preferences—revealing what actually matters to students, researchers and faculty

**You can adjust the weights yourself.** Prioritize affordability, research, or clinical training and see which schools rise. This flexibility helps students find programs matching their values.

## Limitations We Acknowledge

We acknowledge the MCAT and GPA are imperfect proxies for academic ability and are strongly correlated with socioeconomic status. We include them because they remain key admissions criteria; and for all their flaws, are [highly predictive of medical school and board exam performance](https://doi.org/10.1016/j.jnma.2025.08.108). They also help close a crucial feedback loop: if schools want to be highly ranked (or at least not fall behind), they must attract competitive applicants; to attract competitive applicants, they must cater to student priorities; thus, including MCAT and GPA as an index of school rank helps align incentives and drives innovation across the competitive landscape of medical education.

We lack Step 2 scores, unmatched rates, and detailed diversity data—the AAMC has released progressively less information. We'd welcome more transparency on socioeconomic status, race, and first-generation representation. We're working with the best available public dataset, even if incomplete. 

We're also using USNWR specialty rankings as a proxy for clinical excellence, despite their reliance on reputation surveys. Aligning hospitals with medical schools proved complex, especially for institutions like Harvard with multiple affiliates. It's imperfect, but a reasonable starting point.

Rankings aren't perfect. But in their absence, opacity and entrenched prestige win. Better rankings—transparent, data-driven, and accountable—serve students and schools alike.