{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, let's parse the MCAT/GPA data (from shemassian's website)\n",
    "\n",
    "Source: https://www.shemmassianconsulting.com/blog/average-gpa-and-mcat-score-for-every-medical-school\n",
    "\n",
    "Note: I manually updated Vanderbilt's average MCAT/GPA since it wasn't correct on the website.\n",
    "Note: I manually updated Michigan's average MCAT/GPA since it wasn't correct on the website.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "ROOT_DIR = \"/Users/jiturner/Repositories/medical-school-rankings/\"\n",
    "\n",
    "# Point to the NEW .html file you just saved\n",
    "html_path = os.path.join(ROOT_DIR, \"data/raw_inputs/Average GPA and MCAT Score for Every Medical School (2025) — Shemmassian Academic Consulting.html\") \n",
    "\n",
    "# This code should work perfectly now\n",
    "dfs = pd.read_html(html_path, attrs={'id': 'myTable'})\n",
    "df_mcat_gpa = dfs[0]\n",
    "df_mcat_gpa.drop(columns=['Minimum MCAT'], inplace=True)\n",
    "df_mcat_gpa.sort_values(by='Average MCAT', inplace=True, ascending=False)\n",
    "df_mcat_gpa # Drop any rows where Average MCAT is not a number\n",
    "\n",
    "df_mcat_gpa[df_mcat_gpa['Medical School']=='Vanderbilt University School of Medicine']\n",
    "df_mcat_gpa.loc[df_mcat_gpa['Medical School']=='Vanderbilt University School of Medicine', 'Average MCAT'] = 522\n",
    "df_mcat_gpa.loc[df_mcat_gpa['Medical School']=='Vanderbilt University School of Medicine', 'Average GPA'] = 3.94\n",
    "\n",
    "df_mcat_gpa.loc[df_mcat_gpa['Medical School']=='University of Michigan Medical School*', 'Average MCAT'] = 517\n",
    "df_mcat_gpa.loc[df_mcat_gpa['Medical School']=='University of Michigan Medical School*', 'Average GPA'] = 3.92\n",
    "\n",
    "df_mcat_gpa.loc[df_mcat_gpa['Medical School']=='Louisiana State University – New Orleans School of Medicine*', 'Average MCAT'] = 509\n",
    "df_mcat_gpa.loc[df_mcat_gpa['Medical School']=='Louisiana State University – New Orleans School of Medicine*', 'Average GPA'] = 3.76\n",
    "\n",
    "df_mcat_gpa = df_mcat_gpa[pd.to_numeric(df_mcat_gpa['Average MCAT'], errors='coerce').notnull()]\n",
    "# Same for 'Average GPA'.\n",
    "# Then we want two-level sorting: first by Average MCAT (descending), then by Average GPA (descending)\n",
    "df_mcat_gpa = df_mcat_gpa[pd.to_numeric(df_mcat_gpa['Average GPA'], errors='coerce').notnull()]\n",
    "df_mcat_gpa['Average MCAT'] = pd.to_numeric(df_mcat_gpa['Average MCAT'])\n",
    "df_mcat_gpa['Average GPA'] = pd.to_numeric(df_mcat_gpa['Average GPA'])\n",
    "df_mcat_gpa.sort_values(by=['Average MCAT', 'Average GPA'], inplace=True, ascending=[False, False])\n",
    "df_mcat_gpa.reset_index(drop=True, inplace=True)\n",
    "# Convert 'Medical School' to lower case for easier merging later\n",
    "df_mcat_gpa['Medical School'] = df_mcat_gpa['Medical School'].str.lower()\n",
    "df_mcat_gpa['Medical School'] = df_mcat_gpa['Medical School'].str.replace('*', '', regex=False).str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, lets parse Debt Information from MSAR\n",
    "\n",
    "Source: https://students-residents.aamc.org/medical-school-admission-requirements/medical-school-admission-requirements-reports-applicants-and-advisors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:40: SyntaxWarning: invalid escape sequence '\\$'\n",
      "<>:40: SyntaxWarning: invalid escape sequence '\\$'\n",
      "/var/folders/76/y_3kwb_54mx0bh961wd_ycb00000gn/T/ipykernel_52969/2777296739.py:40: SyntaxWarning: invalid escape sequence '\\$'\n",
      "  df_debt_info['Average Graduate\\nIndebtedness'] = pd.to_numeric(df_debt_info['Average Graduate\\nIndebtedness'].str.replace('[\\$,]', '', regex=True), errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 tables across pages 2-7.\n"
     ]
    }
   ],
   "source": [
    "import camelot\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "ROOT_DIR = \"/Users/jiturner/Repositories/medical-school-rankings/\"\n",
    "\n",
    "file_path = os.path.join(ROOT_DIR, 'data/raw_inputs/MSAR014 - MSAR Debt  Information.pdf')\n",
    "\n",
    "# 1. Change pages to the full range\n",
    "tables = camelot.read_pdf(file_path, pages='2-7', flavor='lattice')\n",
    "\n",
    "processed_dfs = [] # 2. Create a list to hold all our DFs\n",
    "\n",
    "if tables.n > 0:\n",
    "    print(f\"Found {tables.n} tables across pages 2-7.\")\n",
    "    \n",
    "    # 3. Loop through every table object\n",
    "    for table in tables:\n",
    "        my_df = table.df\n",
    "        \n",
    "        # Apply your exact header logic to each table\n",
    "        try:\n",
    "            my_df.columns = my_df.iloc[0]\n",
    "            my_df = my_df[1:]\n",
    "            processed_dfs.append(my_df)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not process a table, possibly bad format? Error: {e}\")\n",
    "            print(f\"Problematic table data:\\n{table.df.head()}\\n\")\n",
    "    \n",
    "    # 4. Stack all the individual DataFrames into one\n",
    "    if processed_dfs:\n",
    "        df_debt_info = pd.concat(processed_dfs, ignore_index=True)\n",
    "    else:\n",
    "        df_debt_info = pd.DataFrame() # Empty\n",
    "        \n",
    "else:\n",
    "    print(\"No tables found in that page range.\")\n",
    "    df_debt_info = pd.DataFrame()\n",
    "\n",
    "df_debt_info['Average Graduate\\nIndebtedness'] = pd.to_numeric(df_debt_info['Average Graduate\\nIndebtedness'].str.replace('[\\$,]', '', regex=True), errors='coerce')\n",
    "df_debt_info = df_debt_info[df_debt_info['Average Graduate\\nIndebtedness'].notnull()]\n",
    "df_debt_info.sort_values(by='Average Graduate\\nIndebtedness', ascending=True, inplace=True)\n",
    "df_debt_info.reset_index(drop=True, inplace=True)\n",
    "df_debt_info.head(30)\n",
    "\n",
    "# Let's replace any '*' characters in the 'Medical School' column with an empty string\n",
    "df_debt_info['Medical School'] = df_debt_info['Medical School'].str.replace('*', '', regex=False).str.strip()\n",
    "# Now turn the 'Medical School' to lower case for easier matching later\n",
    "df_debt_info['Medical School'] = df_debt_info['Medical School'].str.lower()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, let's parse NIH funding data from Blue Ridge Institute for Medical Research\n",
    "\n",
    "Source: https://brimr.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ROOT_DIR = \"/Users/jiturner/Repositories/medical-school-rankings/\"\n",
    "file_path = os.path.join(ROOT_DIR, \"data/raw_inputs/SchoolOfMedicine_2024_C.xlsx\")\n",
    "df_nih_funding = pd.read_excel(file_path, sheet_name='2024', header=1)\n",
    "# Currently the 'Name' column is in caps lock, let's make it lower case\n",
    "df_nih_funding['Name'] = df_nih_funding['Name'].str.lower()\n",
    "df_nih_funding.head(25)\n",
    "\n",
    "# However, we're gonna have to add info for some schools manually. Harvard comes to mind (mass general). \n",
    "\n",
    "manual_entries_2024 = [\n",
    "    {'Name': 'massachusetts general hospital', 'School of Medicine Award': 655235087},\n",
    "    {'Name': 'brigham and womens hospital', 'School of Medicine Award': 388162121},\n",
    "    {'Name': 'boston childrens hospital', 'School of Medicine Award': 229894668},\n",
    "    {'Name': 'beth israel deaconess medical center', 'School of Medicine Award': 119860535}\n",
    "]\n",
    "df_manual_2024 = pd.DataFrame(manual_entries_2024)\n",
    "df_nih_funding = pd.concat([df_nih_funding, df_manual_2024], ignore_index=True)\n",
    "df_nih_funding.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, lets parse the Faculty Data from AAMC\n",
    "Source: https://www.aamc.org/data-reports/faculty-institutions/report/faculty-roster-us-medical-school-faculty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ROOT_DIR = \"/Users/jiturner/Repositories/medical-school-rankings/\"\n",
    "file_path = os.path.join(ROOT_DIR, \"data/raw_inputs/U.S. Medical School Faculty, 2024.xlsx\")\n",
    "df_faculty_info = pd.read_excel(file_path, sheet_name='USMSF Table 2', header=3)\n",
    "df_faculty_info = df_faculty_info.iloc[:-3]\n",
    "df_faculty_info.rename(columns={'Total': 'Total Faculty'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, let's parse the USNWR Hospital Rankings Data\n",
    "\n",
    "Got using the usnwr_scraper.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ROOT_DIR = \"/Users/jiturner/Repositories/medical-school-rankings/\"\n",
    "file_path = os.path.join(ROOT_DIR, \"data/raw_hospital_rankings.csv\")\n",
    "df_hospital_rankings_raw = pd.read_csv(file_path)\n",
    "file_path_pivoted_path = os.path.join(ROOT_DIR, \"data/hospital_rankings_pivoted.csv\")\n",
    "df_hospital_rankings_pivoted = pd.read_csv(file_path_pivoted_path)\n",
    "df_hospital_rankings_pivoted # Let's set the 'Institution' to be all lower case\n",
    "df_hospital_rankings_pivoted['Institution'] = df_hospital_rankings_pivoted['Institution'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, Let's Parse Diversity Data\n",
    "\n",
    "**Source: https://www.aamc.org/data-reports/data/2024-facts**, Table B-5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ROOT_DIR = \"/Users/jiturner/Repositories/medical-school-rankings/\"\n",
    "file_path = os.path.join(ROOT_DIR, \"data/raw_inputs/2024_FACTS_Table_B-5.1 - Updated.xlsx\")\n",
    "df_diversity_info = pd.read_excel(file_path, sheet_name='FACTS Table B-5.1', header=4)\n",
    "df_diversity_info = df_diversity_info[df_diversity_info['Total \\nEnrollment'].notnull()]\n",
    "df_diversity_info.rename(columns={'Total Enrollment': 'State', 'Unnamed: 1': 'AAMC_Institution'}, inplace=True)\n",
    "df_diversity_info.rename(columns={'Total \\nEnrollment': 'Total Enrollment'}, inplace=True)\n",
    "# We want to make a column called URM%, which is the summed of 'American Indian \\nor Alaska Native', 'Black or \\nAfrican American', 'Hispanic, Latino, or \\nof Spanish Origin', 'Native Hawaiian or \\nOther Pacific Islander', and then divided by 'Total Enrollment'\n",
    "df_diversity_info['American Indian \\nor Alaska Native'] = pd.to_numeric(df_diversity_info['American Indian \\nor Alaska Native'], errors='coerce').fillna(0)\n",
    "df_diversity_info['Black or \\nAfrican American'] = pd.to_numeric(df_diversity_info['Black or \\nAfrican American'], errors='coerce').fillna(0)\n",
    "df_diversity_info['Hispanic, Latino, or \\nof Spanish Origin '] = pd.to_numeric(df_diversity_info['Hispanic, Latino, or \\nof Spanish Origin '], errors='coerce').fillna(0)\n",
    "df_diversity_info['Native Hawaiian or \\nOther Pacific Islander'] = pd.to_numeric(df_diversity_info['Native Hawaiian or \\nOther Pacific Islander'], errors='coerce').fillna(0)\n",
    "df_diversity_info['Total Enrollment'] = pd.to_numeric(df_diversity_info['Total Enrollment'], errors='coerce').fillna(1) # Avoid division by zero\n",
    "df_diversity_info['URM%'] = (\n",
    "    df_diversity_info['American Indian \\nor Alaska Native'] +\n",
    "    df_diversity_info['Black or \\nAfrican American'] +\n",
    "    df_diversity_info['Hispanic, Latino, or \\nof Spanish Origin '] +\n",
    "    df_diversity_info['Native Hawaiian or \\nOther Pacific Islander']\n",
    ") / df_diversity_info['Total Enrollment'] * 100\n",
    "\n",
    "df_diversity_info.dropna(subset=['AAMC_Institution'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, let's parse class size (2025)\n",
    "Source: https://www.aamc.org/data-reports/students-residents/data/facts-applicants-and-matriculants, Table A-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ROOT_DIR = \"/Users/jiturner/Repositories/medical-school-rankings/\"\n",
    "file_path = os.path.join(ROOT_DIR, \"data/raw_inputs/2025_FACTS_Table_A-1.xlsx\")\n",
    "df_class_size_info = pd.read_excel(file_path, sheet_name='FACTS Table A-1', header=4)\n",
    "df_class_size_info = df_class_size_info[df_class_size_info['Matriculants'].notnull()]\n",
    "df_class_size_info.drop(columns=['Applications'], inplace=True)\n",
    "df_class_size_info.rename(columns={'Matriculants': 'Class Size', 'Applications by School': 'State', 'Unnamed: 1': 'name', 'Applications1':'Applications'}, inplace=True)\n",
    "df_class_size_info = df_class_size_info[['name', 'Applications', 'Class Size']]\n",
    "df_class_size_info.dropna(subset=['name'], inplace=True)\n",
    "df_class_size_info['Matriculation Rate'] = df_class_size_info['Class Size'] / df_class_size_info['Applications'] * 100\n",
    "df_class_size_info.sort_values(by='Matriculation Rate', ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, lets parse tuition and cost of attendance data\n",
    "Source: https://students-residents.aamc.org/medical-school-admission-requirements/medical-school-admission-requirements-reports-applicants-and-advisors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:82: SyntaxWarning: invalid escape sequence '\\$'\n",
      "<>:82: SyntaxWarning: invalid escape sequence '\\$'\n",
      "/var/folders/76/y_3kwb_54mx0bh961wd_ycb00000gn/T/ipykernel_52969/1797820326.py:82: SyntaxWarning: invalid escape sequence '\\$'\n",
      "  df_tuition_info[col] = pd.to_numeric(df_tuition_info[col].str.replace('[\\$,]', '', regex=True), errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 tables across pages 2-11.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['The University of Texas Health Science Center at San Antonio Joe R. and Teresa Lozano Long School of Medicine'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import camelot\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Assuming ROOT_DIR is the same\n",
    "ROOT_DIR = \"/Users/jiturner/Repositories/medical-school-rankings/\"\n",
    "\n",
    "# 1. Update file path\n",
    "file_path = os.path.join(ROOT_DIR, 'data/raw_inputs/MSAR015 - MSAR Tuition,Fees and Insurance Information.pdf')\n",
    "\n",
    "# 2. Update page range\n",
    "tables = camelot.read_pdf(file_path, pages='2-11', flavor='lattice')\n",
    "\n",
    "processed_dfs = [] \n",
    "\n",
    "if tables.n > 0:\n",
    "    print(f\"Found {tables.n} tables across pages 2-11.\")\n",
    "    \n",
    "    # 3. Loop logic updated\n",
    "    for table in tables:\n",
    "        my_df = table.df\n",
    "        \n",
    "        try:\n",
    "            # --- START: New Header Logic ---\n",
    "            \n",
    "            # 1. Get both header rows\n",
    "            super_headers = my_df.iloc[0] # Row 0: ['','', 'In-State', 'In-State', ...]\n",
    "            main_headers = my_df.iloc[1]  # Row 1: ['','Medical School', 'Total Cost...', ...]\n",
    "            \n",
    "            # 2. Fill forward the super-headers so 'In-State' applies to all its columns\n",
    "            super_headers.replace('', pd.NA, inplace=True)\n",
    "            super_headers.ffill(inplace=True) \n",
    "            \n",
    "            # 3. Create new column names\n",
    "            new_cols = []\n",
    "            for sup_head, main_head in zip(super_headers, main_headers):\n",
    "                \n",
    "                if pd.isna(sup_head):\n",
    "                    # This is for 'State' (blank) and 'Medical School'\n",
    "                    new_cols.append(main_head)\n",
    "                else:\n",
    "                    # This is for the In-State/Out-of-State columns\n",
    "                    prefix = 'instate_' if 'In-State' in sup_head else 'outstate_'\n",
    "                    # Clean up newlines in the header name itself\n",
    "                    main_head_clean = main_head.replace('\\n', ' ')\n",
    "                    new_cols.append(f\"{prefix}{main_head_clean}\")\n",
    "                    \n",
    "            # 4. Manually set the first column (which is blank in both rows)\n",
    "            if new_cols[0] == '':\n",
    "                 new_cols[0] = 'State'\n",
    "                 \n",
    "            # 5. Set new columns and skip the 2 header rows\n",
    "            my_df.columns = new_cols\n",
    "            my_df = my_df[2:]\n",
    "            \n",
    "            # --- END: New Header Logic ---\n",
    "            \n",
    "            processed_dfs.append(my_df)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not process a table, possibly bad format? Error: {e}\")\n",
    "            print(f\"Problematic table data:\\n{table.df.head()}\\n\")\n",
    "    \n",
    "    # 4. Stack into a new DataFrame\n",
    "    if processed_dfs:\n",
    "        df_tuition_info = pd.concat(processed_dfs, ignore_index=True)\n",
    "    else:\n",
    "        df_tuition_info = pd.DataFrame() # Empty\n",
    "        \n",
    "else:\n",
    "    print(\"No tables found in that page range.\")\n",
    "    df_tuition_info = pd.DataFrame()\n",
    "\n",
    "df_tuition_info\n",
    "\n",
    "# Convert all cost columns to numeric, removing $ and , first\n",
    "cost_columns = [\n",
    "    'instate_Total Cost of Attendance', 'instate_Health Insurance', 'instate_Tuition and Fees',\n",
    "    'outstate_Total Cost of Attendance', 'outstate_Health Insurance', 'outstate_Tuition and Fees'\n",
    "]\n",
    "for col in cost_columns:\n",
    "    df_tuition_info[col] = pd.to_numeric(df_tuition_info[col].str.replace('[\\$,]', '', regex=True), errors='coerce')\n",
    "\n",
    "# Manually update Albert Einstein College of Medicine tuition data\n",
    "albert_einstein_tuition = 0\n",
    "albert_einstein_insurance = 5465\n",
    "albert_einstein_cost_of_attendance= 35465\n",
    "df_tuition_info.loc[df_tuition_info['Medical School']=='Albert Einstein College of Medicine', 'instate_Total Cost of Attendance'] = albert_einstein_cost_of_attendance\n",
    "df_tuition_info.loc[df_tuition_info['Medical School']=='Albert Einstein College of Medicine', 'instate_Health Insurance'] = albert_einstein_insurance\n",
    "df_tuition_info.loc[df_tuition_info['Medical School']=='Albert Einstein College of Medicine', 'instate_Tuition and Fees'] = albert_einstein_tuition\n",
    "df_tuition_info.loc[df_tuition_info['Medical School']=='Albert Einstein College of Medicine', 'outstate_Total Cost of Attendance'] = albert_einstein_cost_of_attendance\n",
    "df_tuition_info.loc[df_tuition_info['Medical School']=='Albert Einstein College of Medicine', 'outstate_Health Insurance'] = albert_einstein_insurance\n",
    "df_tuition_info.loc[df_tuition_info['Medical School']=='Albert Einstein College of Medicine', 'outstate_Tuition and Fees'] = albert_einstein_tuition\n",
    "\n",
    "# Great! Now we want to consolidate the outstate/instate columns into single columns called 'Tuition and Fees', 'Health Insurance', and 'Total Cost of Attendance'\n",
    "# That will be the MAXIMUM of the two columns for each row\n",
    "df_tuition_info['Tuition and Fees'] = df_tuition_info[['instate_Tuition and Fees', 'outstate_Tuition and Fees']].max(axis=1)\n",
    "df_tuition_info['Health Insurance'] = df_tuition_info[['instate_Health Insurance', 'outstate_Health Insurance']].max(axis=1)\n",
    "df_tuition_info['Total Cost of Attendance'] = df_tuition_info[['instate_Total Cost of Attendance', 'outstate_Total Cost of Attendance']].max(axis=1)\n",
    "# Now sort values by Total Cost of Attendance\n",
    "df_tuition_info['Total Cost of Attendance'] = pd.to_numeric(df_tuition_info['Total Cost of Attendance'], errors='coerce')\n",
    "df_tuition_info.sort_values(by='Total Cost of Attendance', ascending=True, inplace=True)\n",
    "df_tuition_info.reset_index(drop=True, inplace=True)\n",
    "df_tuition_info.rename(columns={'Medical School': 'name'}, inplace=True)\n",
    "# Let's also get rid of \\n characters in the 'name' column\n",
    "df_tuition_info['name'] = df_tuition_info['name'].str.replace('\\n', ' ', regex=False).str.strip()\n",
    "df_tuition_info['name'] = df_tuition_info['name'].str.replace('  ', ' ', regex=False)\n",
    "df_tuition_info['name'] = df_tuition_info['name'].str.strip()\n",
    "# Finally, drop the now-unnecessary columns\n",
    "df_tuition_info.drop(columns=['State', 'instate_Total Cost of Attendance', 'instate_Health Insurance', 'instate_Tuition and Fees',\n",
    "                              'outstate_Total Cost of Attendance', 'outstate_Health Insurance', 'outstate_Tuition and Fees'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure out how to join all the data together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAMC_Institution</th>\n",
       "      <th>Average Graduate Indebtedness</th>\n",
       "      <th>Total Cost of Attendance</th>\n",
       "      <th>Average MCAT</th>\n",
       "      <th>Average GPA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>NYU-Grossman</td>\n",
       "      <td>67572</td>\n",
       "      <td>33612.0</td>\n",
       "      <td>523.00</td>\n",
       "      <td>3.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Vanderbilt</td>\n",
       "      <td>209382</td>\n",
       "      <td>114277.0</td>\n",
       "      <td>522.00</td>\n",
       "      <td>3.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>Yale</td>\n",
       "      <td>91965</td>\n",
       "      <td>111257.0</td>\n",
       "      <td>522.00</td>\n",
       "      <td>3.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Columbia-Vagelos</td>\n",
       "      <td>114362</td>\n",
       "      <td>112753.0</td>\n",
       "      <td>522.00</td>\n",
       "      <td>3.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Pennsylvania-Perelman</td>\n",
       "      <td>150137</td>\n",
       "      <td>112359.0</td>\n",
       "      <td>521.80</td>\n",
       "      <td>3.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Mayo</td>\n",
       "      <td>144152</td>\n",
       "      <td>104034.0</td>\n",
       "      <td>521.00</td>\n",
       "      <td>3.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Johns Hopkins</td>\n",
       "      <td>111516</td>\n",
       "      <td>102460.0</td>\n",
       "      <td>521.00</td>\n",
       "      <td>3.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Chicago-Pritzker</td>\n",
       "      <td>127671</td>\n",
       "      <td>96345.0</td>\n",
       "      <td>521.00</td>\n",
       "      <td>3.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Harvard</td>\n",
       "      <td>118957</td>\n",
       "      <td>107888.0</td>\n",
       "      <td>520.42</td>\n",
       "      <td>3.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>USF-Morsani</td>\n",
       "      <td>193357</td>\n",
       "      <td>88883.0</td>\n",
       "      <td>520.00</td>\n",
       "      <td>3.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Northwestern-Feinberg</td>\n",
       "      <td>191658</td>\n",
       "      <td>112191.0</td>\n",
       "      <td>520.00</td>\n",
       "      <td>3.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>Washington U St Louis</td>\n",
       "      <td>90880</td>\n",
       "      <td>98122.0</td>\n",
       "      <td>519.50</td>\n",
       "      <td>3.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Duke</td>\n",
       "      <td>150488</td>\n",
       "      <td>111338.0</td>\n",
       "      <td>519.00</td>\n",
       "      <td>3.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Stanford</td>\n",
       "      <td>156377</td>\n",
       "      <td>116942.0</td>\n",
       "      <td>519.00</td>\n",
       "      <td>3.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Mount Sinai-Icahn</td>\n",
       "      <td>177369</td>\n",
       "      <td>100309.0</td>\n",
       "      <td>519.00</td>\n",
       "      <td>3.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Baylor</td>\n",
       "      <td>126655</td>\n",
       "      <td>82241.0</td>\n",
       "      <td>518.00</td>\n",
       "      <td>3.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Cornell-Weill</td>\n",
       "      <td>113941</td>\n",
       "      <td>106689.0</td>\n",
       "      <td>518.00</td>\n",
       "      <td>3.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Case Western Reserve</td>\n",
       "      <td>201487</td>\n",
       "      <td>106099.0</td>\n",
       "      <td>518.00</td>\n",
       "      <td>3.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Zucker Hofstra Northwell</td>\n",
       "      <td>152735</td>\n",
       "      <td>101055.0</td>\n",
       "      <td>518.00</td>\n",
       "      <td>3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>UT San Antonio-Long</td>\n",
       "      <td>141428</td>\n",
       "      <td>74478.0</td>\n",
       "      <td>517.70</td>\n",
       "      <td>3.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             AAMC_Institution  Average Graduate Indebtedness  \\\n",
       "59               NYU-Grossman                          67572   \n",
       "148                Vanderbilt                         209382   \n",
       "159                      Yale                          91965   \n",
       "15           Columbia-Vagelos                         114362   \n",
       "68      Pennsylvania-Perelman                         150137   \n",
       "49                       Mayo                         144152   \n",
       "38              Johns Hopkins                         111516   \n",
       "107          Chicago-Pritzker                         127671   \n",
       "33                    Harvard                         118957   \n",
       "93                USF-Morsani                         193357   \n",
       "62      Northwestern-Feinberg                         191658   \n",
       "153     Washington U St Louis                          90880   \n",
       "20                       Duke                         150488   \n",
       "81                   Stanford                         156377   \n",
       "35          Mount Sinai-Icahn                         177369   \n",
       "3                      Baylor                         126655   \n",
       "155             Cornell-Weill                         113941   \n",
       "10       Case Western Reserve                         201487   \n",
       "18   Zucker Hofstra Northwell                         152735   \n",
       "86        UT San Antonio-Long                         141428   \n",
       "\n",
       "     Total Cost of Attendance  Average MCAT  Average GPA  \n",
       "59                    33612.0        523.00         3.98  \n",
       "148                  114277.0        522.00         3.94  \n",
       "159                  111257.0        522.00         3.92  \n",
       "15                   112753.0        522.00         3.90  \n",
       "68                   112359.0        521.80         3.94  \n",
       "49                   104034.0        521.00         3.94  \n",
       "38                   102460.0        521.00         3.92  \n",
       "107                   96345.0        521.00         3.91  \n",
       "33                   107888.0        520.42         3.90  \n",
       "93                    88883.0        520.00         3.95  \n",
       "62                   112191.0        520.00         3.93  \n",
       "153                   98122.0        519.50         3.88  \n",
       "20                   111338.0        519.00         3.90  \n",
       "81                   116942.0        519.00         3.89  \n",
       "35                   100309.0        519.00         3.81  \n",
       "3                     82241.0        518.00         3.91  \n",
       "155                  106689.0        518.00         3.90  \n",
       "10                   106099.0        518.00         3.87  \n",
       "18                   101055.0        518.00         3.86  \n",
       "86                    74478.0        517.70         3.88  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from functools import reduce\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Let's list all the dfs we have so far, along with the key column to join on\n",
    "\n",
    "dataframes = {\n",
    "    'MCAT_GPA': [df_mcat_gpa, 'Medical School'],\n",
    "    'Debt_Info': [df_debt_info, 'Medical School'],\n",
    "    'NIH_Funding': [df_nih_funding, 'Name'],\n",
    "    'Faculty_Info': [df_faculty_info, 'Medical School'],\n",
    "    'Hospital_Rankings': [df_hospital_rankings_pivoted, 'Institution'],\n",
    "    'Diversity': [df_diversity_info, 'AAMC_Institution'],\n",
    "    'Class_Size': [df_class_size_info, 'name'],\n",
    "    'Tuition': [df_tuition_info, 'name']\n",
    "}\n",
    "\n",
    "\n",
    "# Your data (assuming they are loaded)\n",
    "df_mcat_gpa = dataframes['MCAT_GPA'][0]\n",
    "df_debt_info = dataframes['Debt_Info'][0]\n",
    "df_nih_funding = dataframes['NIH_Funding'][0]\n",
    "df_faculty_info = dataframes['Faculty_Info'][0]\n",
    "df_hospital_rankings = dataframes['Hospital_Rankings'][0]\n",
    "df_diversity_info = dataframes['Diversity'][0]\n",
    "df_class_size_info = dataframes['Class_Size'][0]\n",
    "df_tuition_info = dataframes['Tuition'][0]\n",
    "\n",
    "\n",
    "# 1. This is your \"ground truth\" list\n",
    "canonical_schools = df_faculty_info['Medical School'].unique()\n",
    "\n",
    "# 2. This is the \"messy\" list of *all* names from the other sources\n",
    "messy_names = pd.concat([\n",
    "    df_debt_info['Medical School'],\n",
    "    df_nih_funding['Name'],\n",
    "    df_mcat_gpa['Medical School'],\n",
    "    df_hospital_rankings['Institution'],\n",
    "    df_diversity_info['AAMC_Institution'],\n",
    "    df_class_size_info['name'],\n",
    "    df_tuition_info['name']\n",
    "]).unique()\n",
    "\n",
    "messy_names.tolist()\n",
    "\n",
    "with open (os.path.join(ROOT_DIR, 'data/names_mapping.json'), 'r') as f:\n",
    "    name_map = json.load(f)\n",
    "\n",
    "for school in canonical_schools:\n",
    "    name_map[school] = school\n",
    "\n",
    "df_mcat_gpa['canonical_name'] = df_mcat_gpa['Medical School'].map(name_map)\n",
    "df_mcat_gpa.dropna(subset=['canonical_name'], inplace=True)\n",
    "df_debt_info['canonical_name'] = df_debt_info['Medical School'].map(name_map)\n",
    "df_debt_info.dropna(subset=['canonical_name'], inplace=True)\n",
    "df_nih_funding['canonical_name'] = df_nih_funding['Name'].map(name_map)\n",
    "df_nih_funding.dropna(subset=['canonical_name'], inplace=True)\n",
    "df_faculty_info['canonical_name'] = df_faculty_info['Medical School'].map(name_map)\n",
    "df_faculty_info.dropna(subset=['canonical_name'], inplace=True)\n",
    "df_hospital_rankings['canonical_name'] = df_hospital_rankings['Institution'].map(name_map)\n",
    "df_hospital_rankings.dropna(subset=['canonical_name'], inplace=True)\n",
    "df_diversity_info['canonical_name'] = df_diversity_info['AAMC_Institution'].map(name_map)\n",
    "df_diversity_info.dropna(subset=['canonical_name'], inplace=True)\n",
    "df_class_size_info['canonical_name'] = df_class_size_info['name'].map(name_map)\n",
    "df_class_size_info.dropna(subset=['canonical_name'], inplace=True)\n",
    "df_tuition_info['canonical_name'] = df_tuition_info['name'].map(name_map)\n",
    "df_tuition_info.dropna(subset=['canonical_name'], inplace=True)\n",
    "\n",
    "df_nih_funding # Let's see all rows with duplicate Canonical names\n",
    "df_nih_funding_consolidated = df_nih_funding.copy()\n",
    "df_nih_funding_consolidated[df_nih_funding_consolidated.duplicated(subset=['canonical_name'], keep=False)].sort_values(by='canonical_name')\n",
    "df_nih_funding_consolidated = df_nih_funding_consolidated.groupby('canonical_name', as_index=False).agg({'School of Medicine Award': 'sum'})\n",
    "\n",
    "hospital_grouped = df_hospital_rankings.groupby('canonical_name').min(numeric_only=True)\n",
    "hospital_grouped.drop(columns=['#n_ranked_specialties', '#n_top10_specialties', '#n_top1_specialties'], inplace=True, errors='ignore')\n",
    "hospital_grouped_with_cumulative_columns = hospital_grouped.copy()\n",
    "hospital_grouped_with_cumulative_columns['#n_ranked_specialties'] = hospital_grouped.count(axis=1)\n",
    "hospital_grouped_with_cumulative_columns['#n_top10_specialties'] = (hospital_grouped <= 10).sum(axis=1)\n",
    "hospital_grouped_with_cumulative_columns['#n_top1_specialties'] = (hospital_grouped == 1).sum(axis=1)\n",
    "hospital_grouped_with_cumulative_columns.loc['Weill Cornell Medicine'] = hospital_grouped_with_cumulative_columns.loc['Columbia University Vagelos College of Physicians and Surgeons']\n",
    "\n",
    "all_dfs = [\n",
    "    df_mcat_gpa, \n",
    "    df_debt_info, \n",
    "    df_nih_funding_consolidated,\n",
    "    df_faculty_info, \n",
    "    hospital_grouped_with_cumulative_columns,\n",
    "    df_diversity_info,\n",
    "    df_class_size_info,\n",
    "    df_tuition_info\n",
    "]\n",
    "\n",
    "# Drop any rows with \n",
    "\n",
    "final_df = reduce(lambda left, right: pd.merge(left, right, on='canonical_name', how='outer'), all_dfs)\n",
    "final_df.sort_values(by='canonical_name', inplace=True)\n",
    "final_df.rename(columns={'Average Graduate\\nIndebtedness': 'Average Graduate Indebtedness', 'School of Medicine Award': 'NIH Research Funding'}, inplace=True)\n",
    "final_df['NIH Research Funding per Faculty'] = final_df['NIH Research Funding'] / final_df['Total Faculty']\n",
    "columns_we_care_about = ['AAMC_Institution', 'canonical_name', 'Degree Type', 'Average GPA', 'Average MCAT', \n",
    "                        'Average Graduate Indebtedness', 'Tuition and Fees', 'Total Cost of Attendance',\n",
    "                        'NIH Research Funding', 'NIH Research Funding per Faculty', 'Total Faculty',\n",
    "                        '#n_ranked_specialties', '#n_top10_specialties', '#n_top1_specialties',\n",
    "                        'URM%',\n",
    "                        'Applications',\t'Class Size', 'Matriculation Rate',\n",
    "                        'Cancer', \n",
    "                        'Cardiology, Heart & Vascular Surgery', 'Diabetes & Endocrinology',\n",
    "                        'Cardiology, Heart & Vascular Surgery', 'Diabetes & Endocrinology',\n",
    "                        'Ear, Nose & Throat', 'Gastroenterology & GI Surgery', 'Geriatrics',\n",
    "                        'Neurology & Neurosurgery', 'Obstetrics & Gynecology', 'Ophthalmology',\n",
    "                        'Orthopedics', 'Psychiatry', 'Pulmonology & Lung Surgery',\n",
    "                        'Rehabilitation', 'Rheumatology', 'Urology']\n",
    "final_df = final_df[columns_we_care_about]\n",
    "final_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Now let's do a complicated sorting approach-- sort by Average MCAT descending, then by average GPA descending.\n",
    "final_df.sort_values(by=['Average MCAT', 'Average GPA'], ascending=[False, False], inplace=True)\n",
    "\n",
    "\n",
    "final_df.to_csv(os.path.join(ROOT_DIR, 'data/final_medical_school_data.csv'), index=False)\n",
    "\n",
    "final_df[['AAMC_Institution', 'Average Graduate Indebtedness', 'Total Cost of Attendance', 'Average MCAT', 'Average GPA']].head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
